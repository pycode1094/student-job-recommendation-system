import requests
import pandas as pd
from sqlalchemy import create_engine, text
import warnings
import time
from datetime import datetime, timedelta
import logging
import re
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('collect_more_jobs.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def is_target_industry(title, industry, keyword_code):
    """IT, AI, ì „ê¸°, ê¸°ê³„, ë°˜ë„ì²´, ë¡œë´‡, í•´ì–‘ ê´€ë ¨ ì±„ìš©ì¸ì§€ í™•ì¸"""
    target_keywords = [
        'IT', 'AI', 'ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'ë°ì´í„°', 'ë¹…ë°ì´í„°',
        'ì „ê¸°', 'ì „ì', 'ì œì–´', 'ì „ë ¥', 'ë°˜ë„ì²´', 'ì›¨ì´í¼', 'íŒ¨í‚¤ì§•',
        'ê¸°ê³„', 'ì„¤ë¹„', 'ìë™ì°¨', 'ë¡œë´‡', 'ìë™í™”', 'ì œì–´',
        'í•´ì–‘', 'ì¡°ì„ ', 'ì„ ë°•', 'marine', 'iot', 'ì‚¬ë¬¼ì¸í„°ë„·',
        'ì†Œí”„íŠ¸ì›¨ì–´', 'ê°œë°œ', 'í”„ë¡œê·¸ë˜ë°', 'ì‹œìŠ¤í…œ', 'ì†”ë£¨ì…˜'
    ]
    
    # ì œëª©ê³¼ ì‚°ì—…ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
    search_text = f"{title} {industry}".lower()
    
    for keyword in target_keywords:
        if keyword.lower() in search_text:
            return True
    
    return False

def get_extended_job_data():
    """í™•ì¥ëœ ê¸°ê°„ì˜ IT, AI, ì „ê¸°, ê¸°ê³„, ë°˜ë„ì²´, ë¡œë´‡, í•´ì–‘ ê´€ë ¨ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘"""
    access_key = "VOT7qjrkXGwLGfkT0obOaOk7Hb8Wf9pEB75RgvZKNTNd08Ky7a"
    
    # ë‚ ì§œ ë²”ìœ„ í™•ì¥ (ìµœê·¼ 3ê°œì›”)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=90)  # 3ê°œì›” ì „ê¹Œì§€
    
    end_ts = int(end_date.timestamp())
    start_ts = int(start_date.timestamp())
    
    print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    print(f"â° íƒ€ì„ìŠ¤íƒ¬í”„: {start_ts} ~ {end_ts}")
    
    all_records = []
    page = 1
    count = 100  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê°œìˆ˜
    
    while True:
        try:
            print(f"ğŸ“„ {page}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘... (í˜„ì¬ê¹Œì§€ {len(all_records)}ê°œ)")
            
            # Saramin API í˜¸ì¶œ
            url = "https://oapi.saramin.co.kr/job-search"
            params = {
                'access-key': access_key,
                'start': (page - 1) * count,
                'count': count,
                'fields': 'posting-date,expiration-date,keyword-code,count',
                'sort': 'pd',  # ê²Œì‹œì¼ ì—­ìˆœ
                'sr': 'directhire'  # í—¤ë“œí—ŒíŒ…/íŒŒê²¬ì—…ì²´ ì œì™¸
            }
            
            response = requests.get(url, params=params, headers={"Accept": "application/json"})
            
            if response.status_code != 200:
                print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                break
            
            data = response.json()
            job_data = data.get('jobs', {}).get('job', [])
            
            if not job_data:
                print("ğŸ“­ ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            # íƒ€ê²Ÿ ì‚°ì—… í•„í„°ë§
            target_jobs = []
            for job in job_data:
                posting_ts = job.get("posting-timestamp")
                if posting_ts and start_ts <= int(posting_ts) <= end_ts:
                    title = job.get("position", {}).get("title", "")
                    industry = job.get("position", {}).get("industry", {}).get("name", "")
                    keyword_code = job.get("keyword-code", "")
                    
                    if is_target_industry(title, industry, keyword_code):
                        target_jobs.append(job)
            
            print(f"   âœ… {len(target_jobs)}ê°œ íƒ€ê²Ÿ ì±„ìš© ë°œê²¬")
            
            # ë°ì´í„° íŒŒì‹± ë° ì €ì¥
            for job in target_jobs:
                try:
                    record = {
                        "job_id": job.get("id"),
                        "url": job.get("url"),
                        "active": job.get("active"),
                        "company_name": job.get("company", {}).get("detail", {}).get("name"),
                        "company_type": job.get("company", {}).get("detail", {}).get("type", {}).get("name"),
                        "company_size": job.get("company", {}).get("detail", {}).get("size", {}).get("name"),
                        "title": job.get("position", {}).get("title"),
                        "industry": job.get("position", {}).get("industry", {}).get("name"),
                        "industry_code": job.get("position", {}).get("industry", {}).get("code"),
                        "job_type": job.get("position", {}).get("job-type", {}).get("name"),
                        "job_type_code": job.get("position", {}).get("job-type", {}).get("code"),
                        "location": job.get("position", {}).get("location", {}).get("name"),
                        "location_code": job.get("position", {}).get("location", {}).get("code"),
                        "experience": job.get("position", {}).get("experience-level", {}).get("name"),
                        "experience_code": job.get("position", {}).get("experience-level", {}).get("code"),
                        "education": job.get("position", {}).get("required-education-level", {}).get("name"),
                        "education_code": job.get("position", {}).get("required-education-level", {}).get("code"),
                        "salary": job.get("salary", {}).get("name"),
                        "salary_code": job.get("salary", {}).get("code"),
                        "posting_ts": job.get("posting-timestamp"),
                        "expiration_ts": job.get("expiration-timestamp"),
                        "keyword_code": job.get("keyword-code"),
                        "view_count": job.get("count", {}).get("view"),
                        "apply_count": job.get("count", {}).get("apply"),
                        "posting_date": job.get("posting-date"),
                        "expiration_date": job.get("expiration-date"),
                        "collected_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }
                    
                    all_records.append(record)
                    
                except Exception as e:
                    logging.error(f"ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
            time.sleep(0.1)
            
            # ë‹¤ìŒ í˜ì´ì§€ë¡œ
            page += 1
            
            # ì•ˆì „ì¥ì¹˜: ë„ˆë¬´ ë§ì€ í˜ì´ì§€ ìˆ˜ì§‘ ë°©ì§€
            if page > 100:  # ìµœëŒ€ 100í˜ì´ì§€ (10,000ê°œ)
                print("âš ï¸ ìµœëŒ€ í˜ì´ì§€ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break
                
        except Exception as e:
            logging.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            break
    
    print(f"\nğŸ‰ ì´ {len(all_records)}ê°œì˜ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    return all_records

def create_extended_job_table():
    """extended_job_postings í…Œì´ë¸” ìƒì„±"""
    try:
        engine = create_engine(
            'mysql+pymysql://root:15861@127.0.0.1:3306/job_recoder?charset=utf8mb4'
        )
        
        with engine.connect() as connection:
            # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            result = connection.execute(text("SHOW TABLES LIKE 'extended_job_postings'"))
            if result.fetchone():
                print("âœ… extended_job_postings í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                return True
            
            # ìƒˆ í…Œì´ë¸” ìƒì„±
            create_table_sql = """
            CREATE TABLE extended_job_postings (
                id INT AUTO_INCREMENT PRIMARY KEY,
                job_id VARCHAR(50),
                url TEXT,
                active VARCHAR(10),
                company_name VARCHAR(200),
                company_type VARCHAR(100),
                company_size VARCHAR(100),
                title VARCHAR(300),
                industry VARCHAR(100),
                industry_code VARCHAR(20),
                job_type VARCHAR(100),
                job_type_code VARCHAR(20),
                location VARCHAR(200),
                location_code VARCHAR(50),
                experience VARCHAR(100),
                experience_code VARCHAR(20),
                education VARCHAR(100),
                education_code VARCHAR(20),
                salary VARCHAR(100),
                salary_code VARCHAR(20),
                posting_ts BIGINT,
                expiration_ts BIGINT,
                keyword_code TEXT,
                view_count INT,
                apply_count INT,
                posting_date VARCHAR(50),
                expiration_date VARCHAR(50),
                collected_date DATETIME,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            COMMENT='í™•ì¥ëœ ê¸°ê°„ ì±„ìš© ë°ì´í„°'
            """
            
            connection.execute(text(create_table_sql))
            connection.commit()
            print("âœ… extended_job_postings í…Œì´ë¸” ìƒì„± ì™„ë£Œ!")
            return True
            
    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")
        return False

def clear_extended_job_table():
    """extended_job_postings í…Œì´ë¸” ë¹„ìš°ê¸°"""
    try:
        import pymysql
        
        connection = pymysql.connect(
            host='127.0.0.1',
            port=3306,
            user='root',
            password='15861',
            database='job_recoder',
            charset='utf8mb4'
        )
        
        with connection.cursor() as cursor:
            cursor.execute("TRUNCATE TABLE extended_job_postings")
            connection.commit()
        
        connection.close()
        print("âœ… extended_job_postings í…Œì´ë¸” ë¹„ìš°ê¸° ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ë¹„ìš°ê¸° ì˜¤ë¥˜: {e}")

def insert_extended_job_data(records):
    """í™•ì¥ëœ ì±„ìš© ë°ì´í„° ì‚½ì…"""
    try:
        if not records:
            print("âŒ ì‚½ì…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(records)
        
        # ë°ì´í„° íƒ€ì… ì •ë¦¬
        for col in df.columns:
            if col in ['expiration_ts', 'posting_ts']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            elif col in ['view_count', 'apply_count']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’ë“¤ ì •ë¦¬ (ì²« ë²ˆì§¸ ê°’ë§Œ ì‚¬ìš©)
        for col in ['location_code', 'job_type_code', 'industry_code']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.split(',').str[0].str[:50]
        
        # SQLAlchemyë¡œ ë°ì´í„° ì‚½ì…
        engine = create_engine(
            'mysql+pymysql://root:15861@127.0.0.1:3306/job_recoder?charset=utf8mb4'
        )
        
        df.to_sql('extended_job_postings', engine, if_exists='append', index=False)
        
        print(f"âœ… {len(records)}ê°œ ì±„ìš© ë°ì´í„° ì‚½ì… ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: {e}")
        return False

def show_collection_summary():
    """ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    try:
        engine = create_engine(
            'mysql+pymysql://root:15861@127.0.0.1:3306/job_recoder?charset=utf8mb4'
        )
        
        # ì „ì²´ ìˆ˜ì§‘ ë°ì´í„° ìˆ˜
        total_count = pd.read_sql("SELECT COUNT(*) as total FROM extended_job_postings", engine)
        print(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì´ ìˆ˜ì§‘ëœ ì±„ìš©: {total_count.iloc[0]['total']}ê°œ")
        
        # ì‚°ì—…ë³„ ë¶„í¬
        industry_stats = pd.read_sql("""
            SELECT industry, COUNT(*) as count 
            FROM extended_job_postings 
            GROUP BY industry 
            ORDER BY count DESC 
            LIMIT 10
        """, engine)
        
        print(f"\nğŸ­ ì‚°ì—…ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
        for idx, row in industry_stats.iterrows():
            print(f"   â€¢ {row['industry']}: {row['count']}ê°œ")
        
        # ì§€ì—­ë³„ ë¶„í¬
        location_stats = pd.read_sql("""
            SELECT location, COUNT(*) as count 
            FROM extended_job_postings 
            GROUP BY location 
            ORDER BY count DESC 
            LIMIT 10
        """, engine)
        
        print(f"\nğŸ“ ì§€ì—­ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
        for idx, row in location_stats.iterrows():
            print(f"   â€¢ {row['location']}: {row['count']}ê°œ")
        
        # ë¶€ì‚° ì§€ì—­ í™•ì¸
        busan_jobs = pd.read_sql("""
            SELECT company_name, title, industry 
            FROM extended_job_postings 
            WHERE location LIKE '%ë¶€ì‚°%'
            LIMIT 10
        """, engine)
        
        print(f"\nğŸŒŠ ë¶€ì‚° ì§€ì—­ ì±„ìš© (ìƒìœ„ 10ê°œ):")
        if len(busan_jobs) > 0:
            for idx, row in busan_jobs.iterrows():
                print(f"   â€¢ {row['company_name']} - {row['title']} ({row['industry']})")
        else:
            print("   â€¢ ë¶€ì‚° ì§€ì—­ ì±„ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # AI ê´€ë ¨ ì±„ìš©
        ai_jobs = pd.read_sql("""
            SELECT COUNT(*) as count 
            FROM extended_job_postings 
            WHERE title LIKE '%AI%' OR title LIKE '%ì¸ê³µì§€ëŠ¥%' OR title LIKE '%ë¨¸ì‹ ëŸ¬ë‹%'
        """, engine)
        
        print(f"\nğŸ¤– AI ê´€ë ¨ ì±„ìš©: {ai_jobs.iloc[0]['count']}ê°œ")
        
    except Exception as e:
        print(f"âŒ ìš”ì•½ ì¶œë ¥ ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í™•ì¥ëœ ê¸°ê°„ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. í…Œì´ë¸” ìƒì„±
    if not create_extended_job_table():
        return
    
    # 2. ê¸°ì¡´ ë°ì´í„° ë¹„ìš°ê¸°
    clear_extended_job_table()
    
    # 3. ì±„ìš© ë°ì´í„° ìˆ˜ì§‘
    records = get_extended_job_data()
    
    if not records:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 4. ë°ì´í„° ì‚½ì…
    if insert_extended_job_data(records):
        # 5. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        show_collection_summary()
        print("\nğŸ‰ í™•ì¥ëœ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    else:
        print("\nâŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨!")

if __name__ == "__main__":
    main()
