import requests
import pandas as pd
from sqlalchemy import create_engine
import warnings
import time
from datetime import datetime, timedelta
import logging
import re
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_filtered_job_collector.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def is_target_industry(title, industry, keyword_code):
    """IT, ì „ê¸°, ê¸°ê³„, ë°˜ë„ì²´, ë¡œë´‡, í•´ì–‘, AI ê´€ë ¨ ì±„ìš©ì¸ì§€ í™•ì¸"""
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œ ì •ì˜ (AI ë¶„ì•¼ ì¶”ê°€)
    target_keywords = {
        'IT': ['ê°œë°œì', 'í”„ë¡œê·¸ë˜ë¨¸', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ì›¹ê°œë°œ', 'ì•±ê°œë°œ', 'í”„ë¡ íŠ¸ì—”ë“œ', 'ë°±ì—”ë“œ', 
               'í’€ìŠ¤íƒ', 'ë°ì´í„°', 'í´ë¼ìš°ë“œ', 'DevOps', 'ì‹œìŠ¤í…œ', 'ë„¤íŠ¸ì›Œí¬', 'ë³´ì•ˆ', 'ë¸”ë¡ì²´ì¸', 
               'ëª¨ë°”ì¼', 'ê²Œì„', 'UI', 'UX', 'ë””ìì´ë„ˆ', 'ê¸°íšì', 'PM', 'í”„ë¡œë•íŠ¸', 'QA', 'í…ŒìŠ¤í„°', 
               'ì¸í”„ë¼', 'ì„œë²„', 'DB', 'ë°ì´í„°ë² ì´ìŠ¤'],
        
        'AI': ['AI', 'ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'ë¨¸ì‹ ë¹„ì „', 'ì»´í“¨í„°ë¹„ì „', 'ìì—°ì–´ì²˜ë¦¬', 'NLP',
               'ê°•í™”í•™ìŠµ', 'ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤', 'ë°ì´í„°ë¶„ì„', 'ë¹…ë°ì´í„°', 'AIì—”ì§€ë‹ˆì–´', 'AIê°œë°œì',
               'AIì—°êµ¬ì›', 'AIê³¼í•™ì', 'AIì•Œê³ ë¦¬ì¦˜', 'AIí”Œë«í¼', 'AIì†”ë£¨ì…˜', 'AIì„œë¹„ìŠ¤', 'AIëª¨ë¸',
               'AIì‹œìŠ¤í…œ', 'AIê¸°ìˆ ', 'AIí”„ë¡œì íŠ¸', 'AIì œí’ˆ', 'AIì„œë¹„ìŠ¤', 'AIí”Œë«í¼', 'AIì¸í”„ë¼'],
        
        'ì „ê¸°': ['ì „ê¸°', 'ì „ì', 'ì „ë ¥', 'ì „ê¸°ê³µí•™', 'ì „ìê³µí•™', 'ì „ê¸°ì„¤ë¹„', 'ì „ê¸°ì‹œìŠ¤í…œ', 
                'ì „ê¸°ì œì–´', 'ì „ê¸°ì„¤ê³„', 'ì „ê¸°ì‹œê³µ', 'ì „ê¸°ì•ˆì „', 'ì „ê¸°ê¸°ìˆ ', 'ì „ê¸°ì¥ë¹„', 'ì „ê¸°íšŒë¡œ',
                'ì „ê¸°ê³µì‚¬', 'ì „ê¸°ê¸°ì‚¬', 'ì „ê¸°ê¸°ìˆ ì', 'ì „ê¸°ì—”ì§€ë‹ˆì–´', 'ì „ê¸°ê¸°ê¸°', 'ì „ê¸°ì„¤ë¹„ê´€ë¦¬'],
        
        'ê¸°ê³„': ['ê¸°ê³„', 'ê¸°ê³„ê³µí•™', 'ê¸°ê³„ì„¤ê³„', 'ê¸°ê³„ì œì‘', 'ê¸°ê³„ê°€ê³µ', 'ê¸°ê³„ì¡°ë¦½', 'ê¸°ê³„ì •ë¹„',
                'ê¸°ê³„ì„¤ë¹„', 'ê¸°ê³„ì‹œìŠ¤í…œ', 'ê¸°ê³„ì œì–´', 'ê¸°ê³„ê¸°ìˆ ', 'ê¸°ê³„ì¥ë¹„', 'ê¸°ê³„ê³µì‚¬', 'ê¸°ê³„ê¸°ì‚¬',
                'ê¸°ê³„ê¸°ìˆ ì', 'ê¸°ê³„ì—”ì§€ë‹ˆì–´', 'ê¸°ê³„ê¸°ê¸°', 'ê¸°ê³„ì„¤ë¹„ê´€ë¦¬', 'CAD', 'CAM', 'CNC'],
        
        'ë°˜ë„ì²´': ['ë°˜ë„ì²´', 'ë°˜ë„ì²´ê³µí•™', 'ë°˜ë„ì²´ì„¤ê³„', 'ë°˜ë„ì²´ì œì‘', 'ë°˜ë„ì²´ê³µì •', 'ë°˜ë„ì²´ì¥ë¹„',
                   'ë°˜ë„ì²´ê¸°ìˆ ', 'ë°˜ë„ì²´ì—”ì§€ë‹ˆì–´', 'ë°˜ë„ì²´ê¸°ì‚¬', 'ë°˜ë„ì²´ê¸°ìˆ ì', 'ë°˜ë„ì²´ì„¤ë¹„',
                   'ë°˜ë„ì²´ì‹œìŠ¤í…œ', 'ë°˜ë„ì²´ì œì–´', 'ë°˜ë„ì²´ê³µì‚¬', 'ë°˜ë„ì²´ê¸°ê¸°', 'ë°˜ë„ì²´ì„¤ë¹„ê´€ë¦¬',
                   'ì›¨ì´í¼', 'íŒ¨í‚¤ì§•', 'í…ŒìŠ¤íŠ¸', 'ê²€ì‚¬', 'í’ˆì§ˆê´€ë¦¬'],
        
        'ë¡œë´‡': ['ë¡œë´‡', 'ë¡œë´‡ê³µí•™', 'ë¡œë´‡ì„¤ê³„', 'ë¡œë´‡ì œì‘', 'ë¡œë´‡ì œì–´', 'ë¡œë´‡ì‹œìŠ¤í…œ', 'ë¡œë´‡ê¸°ìˆ ',
                'ë¡œë´‡ì—”ì§€ë‹ˆì–´', 'ë¡œë´‡ê¸°ì‚¬', 'ë¡œë´‡ê¸°ìˆ ì', 'ë¡œë´‡ì„¤ë¹„', 'ë¡œë´‡ê³µì‚¬', 'ë¡œë´‡ê¸°ê¸°',
                'ë¡œë´‡ì„¤ë¹„ê´€ë¦¬', 'ìë™í™”', 'ì œì–´', 'ì„¼ì„œ', 'ì•¡ì¶”ì—ì´í„°', 'PLC', 'HMI'],
        
        'í•´ì–‘': ['í•´ì–‘', 'í•´ì–‘ê³µí•™', 'í•´ì–‘ì„¤ê³„', 'í•´ì–‘ì œì‘', 'í•´ì–‘ì‹œìŠ¤í…œ', 'í•´ì–‘ê¸°ìˆ ', 'í•´ì–‘ì—”ì§€ë‹ˆì–´',
                'í•´ì–‘ê¸°ì‚¬', 'í•´ì–‘ê¸°ìˆ ì', 'í•´ì–‘ì„¤ë¹„', 'í•´ì–‘ê³µì‚¬', 'í•´ì–‘ê¸°ê¸°', 'í•´ì–‘ì„¤ë¹„ê´€ë¦¬',
                'ì¡°ì„ ', 'ì¡°ì„ ê³µí•™', 'ì¡°ì„ ì„¤ê³„', 'ì¡°ì„ ì œì‘', 'ì¡°ì„ ì‹œìŠ¤í…œ', 'ì¡°ì„ ê¸°ìˆ ', 'ì¡°ì„ ì—”ì§€ë‹ˆì–´',
                'ì¡°ì„ ê¸°ì‚¬', 'ì¡°ì„ ê¸°ìˆ ì', 'ì¡°ì„ ì„¤ë¹„', 'ì¡°ì„ ê³µì‚¬', 'ì¡°ì„ ê¸°ê¸°', 'ì¡°ì„ ì„¤ë¹„ê´€ë¦¬',
                'ì„ ë°•', 'ì„ ë°•ê³µí•™', 'ì„ ë°•ì„¤ê³„', 'ì„ ë°•ì œì‘', 'ì„ ë°•ì‹œìŠ¤í…œ', 'ì„ ë°•ê¸°ìˆ ', 'ì„ ë°•ì—”ì§€ë‹ˆì–´',
                'ì„ ë°•ê¸°ì‚¬', 'ì„ ë°•ê¸°ìˆ ì', 'ì„ ë°•ì„¤ë¹„', 'ì„ ë°•ê³µì‚¬', 'ì„ ë°•ê¸°ê¸°', 'ì„ ë°•ì„¤ë¹„ê´€ë¦¬']
    }
    
    # ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ ì¡°í•©
    search_text = f"{title} {industry} {keyword_code}".lower()
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ê²€ìƒ‰
    for category, keywords in target_keywords.items():
        for keyword in keywords:
            if keyword.lower() in search_text:
                logging.info(f"âœ… ë§¤ì¹­: {category} - {keyword} in '{title}'")
                return True
    
    return False

def get_enhanced_filtered_job_data():
    """3ì£¼ ì „ë¶€í„° ì§€ê¸ˆê¹Œì§€ì˜ IT, AI, ì „ê¸°, ê¸°ê³„, ë°˜ë„ì²´, ë¡œë´‡, í•´ì–‘ ê´€ë ¨ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘"""
    try:
        access_key = "VOT7qjrkXGwLGfkT0obOaOk7Hb8Wf9pEB75RgvZKNTNd08Ky7a"
        
        # 3ì£¼ ì „ íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°
        three_weeks_ago = datetime.now() - timedelta(weeks=3)
        three_weeks_ago_ts = int(three_weeks_ago.timestamp())
        
        logging.info(f"3ì£¼ ì „ íƒ€ì„ìŠ¤íƒ¬í”„: {three_weeks_ago_ts} ({three_weeks_ago.strftime('%Y-%m-%d %H:%M:%S')})")
        
        # í˜ì´ì§€ë„¤ì´ì…˜ì„ ìœ„í•œ ë³€ìˆ˜
        start = 0
        count = 100
        all_records = []
        filtered_count = 0
        seen_job_ids = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set
        
        # í–¥ìƒëœ API íŒŒë¼ë¯¸í„°
        base_params = {
            'access-key': access_key,
            'count': count,
            'fields': 'posting-date,expiration-date,keyword-code,count',
            'sort': 'pd',  # ê²Œì‹œì¼ ì—­ìˆœ
            'sr': 'directhire'  # í—¤ë“œí—ŒíŒ…/íŒŒê²¬ì—…ì²´ ì œì™¸
        }
        
        page_count = 0
        while True:
            page_count += 1
            params = base_params.copy()
            params['start'] = start
            
            url = "https://oapi.saramin.co.kr/job-search"
            response = requests.get(url, params=params, headers={"Accept": "application/json"})
            data = response.json()
            
            job_data = data.get("jobs", {}).get("job", [])
            
            if not job_data:
                logging.info("ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
                
            if isinstance(job_data, dict):
                job_data = [job_data]
            
            # 3ì£¼ ì´ë‚´ ë°ì´í„°ë§Œ í•„í„°ë§
            filtered_jobs = []
            for job in job_data:
                posting_ts = job.get("posting-timestamp")
                if posting_ts and int(posting_ts) >= three_weeks_ago_ts:
                    filtered_jobs.append(job)
                else:
                    logging.info("3ì£¼ ì´ì „ ë°ì´í„° ë„ë‹¬, ìˆ˜ì§‘ ì¤‘ë‹¨")
                    break
            
            if not filtered_jobs:
                logging.info("í•„í„°ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            # íƒ€ê²Ÿ ì‚°ì—… í•„í„°ë§ ë° ì¤‘ë³µ ì œê±°
            target_jobs = []
            for job in filtered_jobs:
                job_id = job.get("id")
                
                # ì¤‘ë³µ ì²´í¬
                if job_id in seen_job_ids:
                    continue
                
                title = job.get("position", {}).get("title", "")
                industry = job.get("position", {}).get("industry", {}).get("name", "")
                keyword_code = job.get("keyword-code", "")
                
                if is_target_industry(title, industry, keyword_code):
                    target_jobs.append(job)
                    seen_job_ids.add(job_id)  # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ job_id ì¶”ê°€
                    filtered_count += 1
            
            # í–¥ìƒëœ íŒŒì‹±
            for job in target_jobs:
                record = {
                    "job_id": job.get("id"),
                    "url": job.get("url"),
                    "active": job.get("active"),
                    "company_name": job.get("company", {}).get("detail", {}).get("name"),
                    "company_type": job.get("company", {}).get("detail", {}).get("type", {}).get("name"),
                    "company_size": job.get("company", {}).get("detail", {}).get("size", {}).get("name"),
                    "title": job.get("position", {}).get("title"),
                    "industry": job.get("position", {}).get("industry", {}).get("name"),
                    "industry_code": job.get("position", {}).get("industry", {}).get("code"),
                    "job_type": job.get("position", {}).get("job-type", {}).get("name"),
                    "job_type_code": job.get("position", {}).get("job-type", {}).get("code"),
                    "location": job.get("position", {}).get("location", {}).get("name"),
                    "location_code": job.get("position", {}).get("location", {}).get("code"),
                    "experience": job.get("position", {}).get("experience-level", {}).get("name"),
                    "experience_code": job.get("position", {}).get("experience-level", {}).get("code"),
                    "education": job.get("position", {}).get("required-education-level", {}).get("name"),
                    "education_code": job.get("position", {}).get("required-education-level", {}).get("code"),
                    "salary": job.get("salary", {}).get("name"),
                    "salary_code": job.get("salary", {}).get("code"),
                    "posting_ts": job.get("posting-timestamp"),
                    "expiration_ts": job.get("expiration-timestamp"),
                    "keyword_code": job.get("keyword-code"),
                    "view_count": job.get("count", {}).get("view"),
                    "apply_count": job.get("count", {}).get("apply"),
                    "posting_date": job.get("posting-date"),
                    "expiration_date": job.get("expiration-date"),
                }
                all_records.append(record)
            
            logging.info(f"í˜ì´ì§€ {page_count}: {len(filtered_jobs)}ê°œ ì¤‘ {len(target_jobs)}ê°œ í•„í„°ë§ (ì´ {len(all_records)}ê°œ, ì¤‘ë³µì œê±°: {len(seen_job_ids)}ê°œ)")
            
            # ë‹¤ìŒ í˜ì´ì§€ë¡œ
            start += count
            
            # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ë”œë ˆì´
            time.sleep(0.2)  # ë” ë¹ ë¥¸ ìˆ˜ì§‘ì„ ìœ„í•´ ë”œë ˆì´ ë‹¨ì¶•
            
            # ìµœëŒ€ 100í˜ì´ì§€ê¹Œì§€ë§Œ ìˆ˜ì§‘ (10,000ê°œ)
            if page_count >= 100:
                logging.info("ìµœëŒ€ í˜ì´ì§€ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break
        
        logging.info(f"âœ… ì´ {filtered_count}ê°œì˜ íƒ€ê²Ÿ ì±„ìš© ìˆ˜ì§‘ ì™„ë£Œ (ì¤‘ë³µ ì œê±° í›„ {len(all_records)}ê°œ)")
        return all_records
        
    except Exception as e:
        logging.error(f"API ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return []

def clear_enhanced_job_table():
    """enhanced_job_postings í…Œì´ë¸” ë¹„ìš°ê¸°"""
    try:
        import pymysql
        connection = pymysql.connect(
            host='127.0.0.1',
            user='root',
            password='15861',
            port=3306,
            database='job_recoder',
            charset='utf8mb4'
        )
        
        cursor = connection.cursor()
        
        # í…Œì´ë¸” ë¹„ìš°ê¸°
        truncate_sql = "TRUNCATE TABLE enhanced_job_postings"
        cursor.execute(truncate_sql)
        connection.commit()
        
        logging.info("âœ… enhanced_job_postings í…Œì´ë¸” ë¹„ìš°ê¸° ì™„ë£Œ")
        
        cursor.close()
        connection.close()
        
    except Exception as e:
        logging.error(f"âŒ í…Œì´ë¸” ë¹„ìš°ê¸° ì˜¤ë¥˜: {e}")

def insert_enhanced_filtered_job_data(records):
    """í•„í„°ë§ëœ ì±„ìš© ë°ì´í„° ì‚½ì…"""
    try:
        if not records:
            logging.info("ì‚½ì…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        df = pd.DataFrame(records)
        
        # SQLAlchemy ì—”ì§„ ìƒì„±
        engine = create_engine(
            'mysql+pymysql://root:15861@127.0.0.1:3306/job_recoder?charset=utf8mb4'
        )
        
        # ë°ì´í„° ì‚½ì…
        df.to_sql('enhanced_job_postings', engine, if_exists='append', index=False)
        
        logging.info(f"âœ… {len(records)}ê°œ ë°ì´í„° ì‚½ì… ì™„ë£Œ")
        
    except Exception as e:
        logging.error(f"âŒ ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í–¥ìƒëœ í•„í„°ë§ëœ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    # 1. í…Œì´ë¸” ë¹„ìš°ê¸°
    print("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
    clear_enhanced_job_table()
    
    # 2. í•„í„°ë§ëœ ë°ì´í„° ìˆ˜ì§‘
    print("ğŸ“Š IT, AI, ì „ê¸°, ê¸°ê³„, ë°˜ë„ì²´, ë¡œë´‡, í•´ì–‘ ê´€ë ¨ ì±„ìš© ìˆ˜ì§‘ ì¤‘...")
    print("ğŸ“… 3ì£¼ ì „ë¶€í„° ì§€ê¸ˆê¹Œì§€ì˜ ëª¨ë“  ê³µê³  ìˆ˜ì§‘...")
    records = get_enhanced_filtered_job_data()
    
    if not records:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 3. ë°ì´í„° ì‚½ì…
    print(f"ğŸ’¾ {len(records)}ê°œ ë°ì´í„° ì‚½ì… ì¤‘...")
    insert_enhanced_filtered_job_data(records)
    
    print("âœ… í–¥ìƒëœ í•„í„°ë§ëœ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    
    # 4. í†µê³„ ì¶œë ¥
    print(f"\nğŸ“ˆ ìˆ˜ì§‘ í†µê³„:")
    print(f"   - ì´ ìˆ˜ì§‘ëœ ì±„ìš©: {len(records)}ê°œ")
    
    # ì‚°ì—…ë³„ í†µê³„
    df = pd.DataFrame(records)
    if not df.empty:
        industry_stats = df['industry'].value_counts().head(10)
        print(f"   - ìƒìœ„ ì‚°ì—…:")
        for industry, count in industry_stats.items():
            print(f"     â€¢ {industry}: {count}ê°œ")
        
        # AI ê´€ë ¨ ì±„ìš© í†µê³„
        ai_jobs = df[df['title'].str.contains('AI|ì¸ê³µì§€ëŠ¥|ë¨¸ì‹ ëŸ¬ë‹|ë”¥ëŸ¬ë‹', case=False, na=False)]
        print(f"   - AI ê´€ë ¨ ì±„ìš©: {len(ai_jobs)}ê°œ")

if __name__ == "__main__":
    main()
