import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
import logging
import re
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
import warnings
from datetime import datetime
import random
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_recommendation_system.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class EnhancedRecommendationSystem:
    def __init__(self):
        """í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # SBERT ëª¨ë¸ ë¡œë“œ
            print("ğŸ¤– SBERT ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
            self.model = SentenceTransformer('xlm-r-100langs-bert-base-nli-stsb-mean-tokens')
            print("âœ… SBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ SBERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ sentence-transformers íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install sentence-transformers")
            return None
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.engine = create_engine(
            'mysql+pymysql://root:15861@127.0.0.1:3306/job_recoder?charset=utf8mb4'
        )
        
        # ì •êµí•œ ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
        self.weights = {
            'semantic_similarity': 0.35,    # SBERT ì˜ë¯¸ì  ìœ ì‚¬ë„ (ê°€ì¥ ì¤‘ìš”)
            'course_industry_match': 0.25,  # ê³¼ì •-ì‚°ì—… ë§¤ì¹­
            'location_preference': 0.20,    # ì§€ì—­ ì„ í˜¸ë„
            'company_diversity': 0.15,      # íšŒì‚¬ ë‹¤ì–‘ì„±
            'freshness_bonus': 0.05         # ìµœì‹ ì„± ë³´ë„ˆìŠ¤
        }
        
        # ì§€ì—­ë³„ ê°€ì¤‘ì¹˜ (ë¶€ì‚° ì§€ì—­ ìš°ì„ )
        self.location_weights = {
            'ë¶€ì‚°': 1.2,      # ë¶€ì‚° ì§€ì—­ ê°€ì¤‘ì¹˜ ì¦ê°€
            'ìš¸ì‚°': 1.1,      # ìš¸ì‚° ì§€ì—­ ê°€ì¤‘ì¹˜ ì¦ê°€
            'ê²½ë‚¨': 1.05,     # ê²½ë‚¨ ì§€ì—­ ê°€ì¤‘ì¹˜ ì¦ê°€
            'ì„œìš¸': 0.95,     # ì„œìš¸ ì§€ì—­ ê°€ì¤‘ì¹˜ ê°ì†Œ
            'ê²½ê¸°': 0.9       # ê²½ê¸° ì§€ì—­ ê°€ì¤‘ì¹˜ ê°ì†Œ
        }
        
        # ì‚°ì—…ë³„ ê°€ì¤‘ì¹˜ (ë°˜ë„ì²´/IT ìš°ì„ )
        self.industry_weights = {
            'ë°˜ë„ì²´Â·ê´‘í•™Â·LCD': 1.3,
            'AIÂ·ì¸ê³µì§€ëŠ¥': 1.25,
            'ì „ê¸°Â·ì „ìÂ·ì œì–´': 1.2,
            'ê¸°ê³„Â·ì„¤ë¹„Â·ìë™ì°¨': 1.1,
            'ì†”ë£¨ì…˜Â·SIÂ·ERPÂ·CRM': 1.15,
            'ê¸°íƒ€': 0.8
        }
        
        self.logger = logging.getLogger(__name__)
        
        # ë‹¤ì–‘ì„± í™•ë³´ë¥¼ ìœ„í•œ ë³€ìˆ˜
        self.used_companies = set()
        self.used_locations = set()
        self.used_industries = set()
    
    def create_enhanced_testresult_table(self):
        """í–¥ìƒëœ testresult í…Œì´ë¸” ìƒì„±"""
        try:
            print("ğŸ”§ í–¥ìƒëœ testresult í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤...")
            
            with self.engine.connect() as connection:
                # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
                connection.execute(text("DROP TABLE IF EXISTS enhanced_testresult"))
                connection.commit()
                print("âœ… ê¸°ì¡´ enhanced_testresult í…Œì´ë¸” ì‚­ì œ ì™„ë£Œ")
                
                # ìƒˆ í…Œì´ë¸” ìƒì„±
                create_table_sql = """
                CREATE TABLE enhanced_testresult (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    student_id VARCHAR(20),
                    student_name VARCHAR(50),
                    course_name VARCHAR(100),
                    survey_responses TEXT,
                    recommended_job_id VARCHAR(50),
                    recommended_company VARCHAR(200),
                    recommended_title VARCHAR(300),
                    recommended_industry VARCHAR(100),
                    recommended_location VARCHAR(200),
                    recommended_job_type VARCHAR(100),
                    semantic_similarity DECIMAL(5,4),
                    course_industry_score DECIMAL(5,4),
                    location_score DECIMAL(5,4),
                    diversity_score DECIMAL(5,4),
                    freshness_score DECIMAL(5,4),
                    final_score DECIMAL(5,4),
                    recommendation_rank INT,
                    diversity_penalty DECIMAL(5,4),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
                COMMENT='í–¥ìƒëœ í•™ìƒë³„ ì¶”ì²œ ê²°ê³¼ í…Œì´ë¸”'
                """
                connection.execute(text(create_table_sql))
                connection.commit()
                print("âœ… ìƒˆë¡œìš´ enhanced_testresult í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")
            return False
    
    def load_and_merge_job_data(self):
        """ëª¨ë“  ì±„ìš© ë°ì´í„° ë¡œë“œ ë° í†µí•©"""
        try:
            print("ğŸ“Š ì±„ìš© ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  í†µí•©í•©ë‹ˆë‹¤...")
            
            # 1. ê¸°ì¡´ job_postings ë°ì´í„°
            try:
                job_postings_df = pd.read_sql("SELECT * FROM job_postings", self.engine)
                print(f"   ğŸ“‹ job_postings: {len(job_postings_df)}ê°œ")
            except Exception as e:
                print(f"   âš ï¸ job_postings í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤: {e}")
                job_postings_df = pd.DataFrame()
            
            # 2. extended_job_postings ë°ì´í„°
            try:
                extended_df = pd.read_sql("SELECT * FROM extended_job_postings", self.engine)
                print(f"   ğŸ“‹ extended_job_postings: {len(extended_df)}ê°œ")
            except Exception as e:
                print(f"   âš ï¸ extended_job_postings í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤: {e}")
                extended_df = pd.DataFrame()
            
            # 3. ë°ì´í„° í†µí•©
            if not job_postings_df.empty and not extended_df.empty:
                # ì¤‘ë³µ ì œê±° (job_id ê¸°ì¤€)
                all_jobs = pd.concat([job_postings_df, extended_df], ignore_index=True)
                all_jobs = all_jobs.drop_duplicates(subset=['job_id'], keep='first')
                print(f"   ğŸ”— í†µí•© í›„ ì¤‘ë³µ ì œê±°: {len(all_jobs)}ê°œ")
            elif not job_postings_df.empty:
                all_jobs = job_postings_df
            elif not extended_df.empty:
                all_jobs = extended_df
            else:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # 4. ë°ì´í„° ì •ë¦¬
            all_jobs = all_jobs.fillna('')
            
            # 5. ë§Œë£Œëœ ê³µê³  ì œê±°
            current_ts = int(datetime.now().timestamp())
            if 'expiration_ts' in all_jobs.columns:
                all_jobs['expiration_ts'] = pd.to_numeric(all_jobs['expiration_ts'], errors='coerce')
                active_jobs = all_jobs[all_jobs['expiration_ts'] > current_ts]
                print(f"   ğŸ—‘ï¸ ë§Œë£Œëœ ê³µê³  ì œê±°: {len(all_jobs) - len(active_jobs)}ê°œ")
                all_jobs = active_jobs
            
            print(f"âœ… ìµœì¢… ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ìš© ê³µê³ : {len(all_jobs)}ê°œ")
            return all_jobs
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    def prepare_student_profiles(self):
        """í•™ìƒ í”„ë¡œí•„ ì¤€ë¹„ ë° í–¥ìƒ"""
        try:
            print("\nğŸ‘¥ í•™ìƒ í”„ë¡œí•„ì„ ì¤€ë¹„í•©ë‹ˆë‹¤...")
            
            beta_test_df = pd.read_sql("SELECT * FROM RecoderBetaTest", self.engine)
            student_profiles = []
            
            for idx, row in beta_test_df.iterrows():
                # í•™ìƒ ê¸°ë³¸ ì •ë³´
                student_id = row.get('student_id', f'student_{idx}')
                student_name = row.get('ì´ë¦„ì„_ì…ë ¥í•´ì£¼ì„¸ìš”', 'Unknown')
                course_name = row.get('ê³¼ì •ëª…ì„_í™•ì¸í•´ì£¼ì„¸ìš”ë§ìœ¼ë©´_ì„ íƒ', 'Unknown')
                
                # ì„¤ë¬¸ ì‘ë‹µ ë‚´ìš©ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
                survey_texts = []
                for col in beta_test_df.columns:
                    if col not in ['id', 'student_id', 'ì´ë¦„ì„_ì…ë ¥í•´ì£¼ì„¸ìš”', 'ê³¼ì •ëª…ì„_í™•ì¸í•´ì£¼ì„¸ìš”ë§ìœ¼ë©´_ì„ íƒ']:
                        value = row.get(col, '')
                        if pd.notna(value) and str(value).strip():
                            survey_texts.append(f"{col}: {value}")
                
                survey_responses = " | ".join(survey_texts)
                
                # ê³¼ì •ëª…ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
                course_keywords = self.extract_enhanced_course_keywords(course_name)
                
                # ì§€ì—­ ì„ í˜¸ë„ ì¶”ì¶œ (ì„¤ë¬¸ì—ì„œ)
                location_preference = self.extract_location_preference(survey_responses)
                
                profile = {
                    'student_id': student_id,
                    'student_name': student_name,
                    'course_name': course_name,
                    'survey_responses': survey_responses,
                    'course_keywords': course_keywords,
                    'location_preference': location_preference,
                    'semantic_embedding': None  # ë‚˜ì¤‘ì— ê³„ì‚°
                }
                
                student_profiles.append(profile)
            
            print(f"âœ… {len(student_profiles)}ëª…ì˜ í•™ìƒ í”„ë¡œí•„ ì¤€ë¹„ ì™„ë£Œ")
            return student_profiles
            
        except Exception as e:
            print(f"âŒ í•™ìƒ í”„ë¡œí•„ ì¤€ë¹„ ì˜¤ë¥˜: {e}")
            return None
    
    def extract_enhanced_course_keywords(self, course_name):
        """í–¥ìƒëœ ê³¼ì •ëª… í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if pd.isna(course_name):
            return ""
        
        course_name = str(course_name).lower()
        
        # ë” ì •êµí•œ í‚¤ì›Œë“œ ë§¤í•‘
        keyword_mapping = {
            'ai': ['ai', 'ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'neural', 'algorithm'],
            'iot': ['iot', 'ì‚¬ë¬¼ì¸í„°ë„·', 'ì¸í„°ë„·', 'ì„¼ì„œ', 'sensor', 'network'],
            'ë°˜ë„ì²´': ['ë°˜ë„ì²´', 'semiconductor', 'ì›¨ì´í¼', 'wafer', 'íŒ¨í‚¤ì§•', 'packaging', 'fab'],
            'ì „ê¸°': ['ì „ê¸°', 'ì „ì', 'ì „ë ¥', 'electric', 'electronic', 'power', 'circuit'],
            'ê¸°ê³„': ['ê¸°ê³„', 'mechanical', 'ì„¤ê³„', 'design', 'ì œì‘', 'manufacturing', 'cad'],
            'ë¡œë´‡': ['ë¡œë´‡', 'robot', 'ìë™í™”', 'automation', 'ì œì–´', 'control', 'motion'],
            'í•´ì–‘': ['í•´ì–‘', 'marine', 'ì¡°ì„ ', 'shipbuilding', 'ì„ ë°•', 'vessel', 'offshore'],
            'it': ['it', 'ê°œë°œ', 'development', 'í”„ë¡œê·¸ë˜ë°', 'programming', 'ì†Œí”„íŠ¸ì›¨ì–´', 'software'],
            'ë°ì´í„°': ['ë°ì´í„°', 'data', 'ë¶„ì„', 'analysis', 'ë¹…ë°ì´í„°', 'bigdata', 'mining'],
            'ì‹œìŠ¤í…œ': ['ì‹œìŠ¤í…œ', 'system', 'ì•„í‚¤í…ì²˜', 'architecture', 'ì¸í”„ë¼', 'infrastructure']
        }
        
        extracted_keywords = []
        for category, keywords in keyword_mapping.items():
            for keyword in keywords:
                if keyword in course_name:
                    extracted_keywords.append(category)
                    break
        
        return " ".join(extracted_keywords)
    
    def extract_location_preference(self, survey_responses):
        """ì„¤ë¬¸ì—ì„œ ì§€ì—­ ì„ í˜¸ë„ ì¶”ì¶œ"""
        if pd.isna(survey_responses):
            return []
        
        responses = str(survey_responses).lower()
        
        # ì§€ì—­ í‚¤ì›Œë“œ ë§¤í•‘
        location_keywords = {
            'ë¶€ì‚°': ['ë¶€ì‚°', 'busan', 'í•´ìš´ëŒ€', 'ë™ë˜', 'ì„œë©´', 'ë‚¨í¬ë™'],
            'ì„œìš¸': ['ì„œìš¸', 'seoul', 'ê°•ë‚¨', 'í™ëŒ€', 'ê°•ë¶', 'ì¢…ë¡œ'],
            'ìš¸ì‚°': ['ìš¸ì‚°', 'ulsan', 'ìš¸ì£¼', 'ë‚¨êµ¬', 'ë™êµ¬', 'ë¶êµ¬'],
            'ê²½ë‚¨': ['ê²½ë‚¨', 'ê²½ìƒë‚¨ë„', 'ê¹€í•´', 'ì–‘ì‚°', 'ì°½ì›', 'ì§„ì£¼'],
            'ê²½ê¸°': ['ê²½ê¸°', 'ê²½ê¸°ë„', 'ì„±ë‚¨', 'ìˆ˜ì›', 'ì•ˆì–‘', 'í™”ì„±'],
            'ì¸ì²œ': ['ì¸ì²œ', 'incheon', 'ì†¡ë„', 'ì—°ìˆ˜', 'ë‚¨ë™', 'ë¶€í‰']
        }
        
        preferred_locations = []
        for location, keywords in location_keywords.items():
            for keyword in keywords:
                if keyword in responses:
                    preferred_locations.append(location)
                    break
        
        return preferred_locations
    
    def calculate_semantic_similarity(self, student_profile, job_data):
        """SBERTë¥¼ ì‚¬ìš©í•œ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            if not student_profile['course_keywords'] or not job_data.get('title'):
                return 0.0
            
            # í•™ìƒ ê³¼ì • í‚¤ì›Œë“œì™€ ì±„ìš© ì œëª© ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„
            course_text = student_profile['course_keywords']
            job_text = f"{job_data.get('title', '')} {job_data.get('industry', '')}"
            
            # SBERT ì„ë² ë”© ìƒì„±
            course_embedding = self.model.encode([course_text])
            job_embedding = self.model.encode([job_text])
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = cosine_similarity(course_embedding, job_embedding)[0][0]
            
            return float(similarity)
            
        except Exception as e:
            self.logger.error(f"ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def calculate_course_industry_match(self, student_profile, job_data):
        """ê³¼ì •-ì‚°ì—… ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        try:
            course_keywords = student_profile['course_keywords'].lower()
            industry = str(job_data.get('industry', '')).lower()
            title = str(job_data.get('title', '')).lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            match_score = 0.0
            
            # ë°˜ë„ì²´ ê´€ë ¨
            if any(keyword in course_keywords for keyword in ['ë°˜ë„ì²´', 'semiconductor']):
                if any(keyword in industry + ' ' + title for keyword in ['ë°˜ë„ì²´', 'semiconductor', 'wafer', 'fab']):
                    match_score += 0.8
            
            # AI ê´€ë ¨
            if any(keyword in course_keywords for keyword in ['ai', 'ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹']):
                if any(keyword in industry + ' ' + title for keyword in ['ai', 'ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹']):
                    match_score += 0.8
            
            # ì „ê¸°/ì „ì ê´€ë ¨
            if any(keyword in course_keywords for keyword in ['ì „ê¸°', 'ì „ì', 'electric']):
                if any(keyword in industry + ' ' + title for keyword in ['ì „ê¸°', 'ì „ì', 'electric', 'electronic']):
                    match_score += 0.7
            
            # ê¸°ê³„ ê´€ë ¨
            if any(keyword in course_keywords for keyword in ['ê¸°ê³„', 'mechanical']):
                if any(keyword in industry + ' ' + title for keyword in ['ê¸°ê³„', 'mechanical', 'ì„¤ê³„', 'design']):
                    match_score += 0.7
            
            # IoT ê´€ë ¨
            if any(keyword in course_keywords for keyword in ['iot', 'ì‚¬ë¬¼ì¸í„°ë„·']):
                if any(keyword in industry + ' ' + title for keyword in ['iot', 'ì‚¬ë¬¼ì¸í„°ë„·', 'ì„¼ì„œ', 'sensor']):
                    match_score += 0.7
            
            return min(match_score, 1.0)
            
        except Exception as e:
            self.logger.error(f"ê³¼ì •-ì‚°ì—… ë§¤ì¹­ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def calculate_location_score(self, student_profile, job_data):
        """ì§€ì—­ ì ìˆ˜ ê³„ì‚°"""
        try:
            location = str(job_data.get('location', '')).lower()
            preferred_locations = student_profile['location_preference']
            
            # ê¸°ë³¸ ì§€ì—­ ì ìˆ˜
            base_score = 0.5
            
            # ì„ í˜¸ ì§€ì—­ê³¼ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
            for preferred in preferred_locations:
                if preferred.lower() in location:
                    base_score += 0.3
                    break
            
            # ì§€ì—­ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            for region, weight in self.location_weights.items():
                if region in location:
                    base_score *= weight
                    break
            
            return min(base_score, 1.0)
            
        except Exception as e:
            self.logger.error(f"ì§€ì—­ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5
    
    def calculate_diversity_score(self, student_profile, job_data, current_recommendations):
        """ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚° (ì¤‘ë³µ íšŒì‚¬/ì§€ì—­/ì‚°ì—… í˜ë„í‹°)"""
        try:
            diversity_score = 1.0
            
            # íšŒì‚¬ ì¤‘ë³µ í˜ë„í‹°
            company = job_data.get('company_name', '')
            if company in self.used_companies:
                diversity_score -= 0.3
            
            # ì§€ì—­ ì¤‘ë³µ í˜ë„í‹°
            location = job_data.get('location', '')
            if location in self.used_locations:
                diversity_score -= 0.2
            
            # ì‚°ì—… ì¤‘ë³µ í˜ë„í‹°
            industry = job_data.get('industry', '')
            if industry in self.used_industries:
                diversity_score -= 0.2
            
            # í˜„ì¬ í•™ìƒì˜ ê¸°ì¡´ ì¶”ì²œê³¼ ì¤‘ë³µ ì²´í¬
            student_id = student_profile['student_id']
            if student_id in current_recommendations:
                existing_companies = set()
                existing_locations = set()
                existing_industries = set()
                
                for rec in current_recommendations[student_id]:
                    existing_companies.add(rec.get('company', ''))
                    existing_locations.add(rec.get('location', ''))
                    existing_industries.add(rec.get('industry', ''))
                
                if company in existing_companies:
                    diversity_score -= 0.4
                if location in existing_locations:
                    diversity_score -= 0.3
                if industry in existing_industries:
                    diversity_score -= 0.3
            
            return max(diversity_score, 0.1)  # ìµœì†Œ 0.1ì  ë³´ì¥
            
        except Exception as e:
            self.logger.error(f"ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5
    
    def calculate_freshness_score(self, job_data):
        """ìµœì‹ ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            posting_ts = job_data.get('posting_ts')
            if not posting_ts:
                return 0.5
            
            posting_ts = int(posting_ts)
            current_ts = int(datetime.now().timestamp())
            
            # ê²Œì‹œëœ ì§€ ì–¼ë§ˆë‚˜ ë˜ì—ˆëŠ”ì§€ ê³„ì‚° (ì¼ ë‹¨ìœ„)
            days_ago = (current_ts - posting_ts) / (24 * 3600)
            
            # ìµœì‹ ì„± ì ìˆ˜ (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            if days_ago <= 7:      # 1ì£¼ì¼ ì´ë‚´
                return 1.0
            elif days_ago <= 30:   # 1ê°œì›” ì´ë‚´
                return 0.8
            elif days_ago <= 90:   # 3ê°œì›” ì´ë‚´
                return 0.6
            else:                   # 3ê°œì›” ì´ìƒ
                return 0.4
                
        except Exception as e:
            self.logger.error(f"ìµœì‹ ì„± ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5
    
    def calculate_final_score(self, scores):
        """ìµœì¢… ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )"""
        try:
            final_score = (
                scores['semantic_similarity'] * self.weights['semantic_similarity'] +
                scores['course_industry_match'] * self.weights['course_industry_match'] +
                scores['location_score'] * self.weights['location_preference'] +
                scores['diversity_score'] * self.weights['company_diversity'] +
                scores['freshness_score'] * self.weights['freshness_bonus']
            )
            
            return round(final_score, 4)
            
        except Exception as e:
            self.logger.error(f"ìµœì¢… ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def generate_enhanced_recommendations(self, student_profiles, job_data_df):
        """í–¥ìƒëœ ì¶”ì²œ ìƒì„±"""
        print("\nğŸ¯ í–¥ìƒëœ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤...")
        
        all_recommendations = []
        current_recommendations = {}  # í•™ìƒë³„ í˜„ì¬ ì¶”ì²œ ì¶”ì 
        
        for student in student_profiles:
            print(f"ğŸ“‹ {student['student_name']} ({student['course_name']}) í–¥ìƒëœ ì¶”ì²œ ìƒì„± ì¤‘...")
            
            # í•™ìƒë³„ ì¶”ì²œ ì´ˆê¸°í™”
            current_recommendations[student['student_id']] = []
            
            # ëª¨ë“  ì±„ìš© ê³µê³ ì™€ì˜ ì ìˆ˜ ê³„ì‚°
            job_scores = []
            
            for idx, job in job_data_df.iterrows():
                try:
                    # ê° í•­ëª©ë³„ ì ìˆ˜ ê³„ì‚°
                    semantic_score = self.calculate_semantic_similarity(student, job)
                    course_industry_score = self.calculate_course_industry_match(student, job)
                    location_score = self.calculate_location_score(student, job)
                    diversity_score = self.calculate_diversity_score(student, job, current_recommendations)
                    freshness_score = self.calculate_freshness_score(job)
                    
                    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
                    final_score = self.calculate_final_score({
                        'semantic_similarity': semantic_score,
                        'course_industry_match': course_industry_score,
                        'location_score': location_score,
                        'diversity_score': diversity_score,
                        'freshness_score': freshness_score
                    })
                    
                    job_scores.append({
                        'job_id': job.get('job_id'),
                        'company': job.get('company_name'),
                        'title': job.get('title'),
                        'industry': job.get('industry'),
                        'location': job.get('location'),
                        'job_type': job.get('job_type'),
                        'semantic_similarity': semantic_score,
                        'course_industry_score': course_industry_score,
                        'location_score': location_score,
                        'diversity_score': diversity_score,
                        'freshness_score': freshness_score,
                        'final_score': final_score
                    })
                    
                except Exception as e:
                    self.logger.error(f"ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
                    continue
            
            # ìµœì¢… ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 5ê°œ ì„ íƒ
            job_scores.sort(key=lambda x: x['final_score'], reverse=True)
            top_5_recommendations = job_scores[:5]
            
            # ì¶”ì²œ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            for rank, rec in enumerate(top_5_recommendations, 1):
                recommendation = {
                    'student_id': student['student_id'],
                    'student_name': student['student_name'],
                    'course_name': student['course_name'],
                    'survey_responses': student['survey_responses'],
                    'recommended_job_id': rec['job_id'],
                    'recommended_company': rec['company'],
                    'recommended_title': rec['title'],
                    'recommended_industry': rec['industry'],
                    'recommended_location': rec['location'],
                    'recommended_job_type': rec['job_type'],
                    'semantic_similarity': rec['semantic_similarity'],
                    'course_industry_score': rec['course_industry_score'],
                    'location_score': rec['location_score'],
                    'diversity_score': rec['diversity_score'],
                    'freshness_score': rec['freshness_score'],
                    'final_score': rec['final_score'],
                    'recommendation_rank': rank,
                    'diversity_penalty': 1.0 - rec['diversity_score']
                }
                
                all_recommendations.append(recommendation)
                current_recommendations[student['student_id']].append({
                    'company': rec['company'],
                    'location': rec['location'],
                    'industry': rec['industry']
                })
                
                # ë‹¤ì–‘ì„± ì¶”ì  ì—…ë°ì´íŠ¸
                self.used_companies.add(rec['company'])
                self.used_locations.add(rec['location'])
                self.used_industries.add(rec['industry'])
            
            print(f"   âœ… {len(top_5_recommendations)}ê°œ í–¥ìƒëœ ì¶”ì²œ ì™„ë£Œ")
        
        print(f"\nğŸ‰ ì´ {len(all_recommendations)}ê°œì˜ í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ ìƒì„± ì™„ë£Œ!")
        return all_recommendations
    
    def save_enhanced_recommendations(self, recommendations):
        """í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ë¥¼ enhanced_testresult í…Œì´ë¸”ì— ì €ì¥"""
        try:
            print("\nğŸ’¾ í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤...")
            
            df = pd.DataFrame(recommendations)
            
            # ë°ì´í„° ì‚½ì…
            df.to_sql('enhanced_testresult', self.engine, if_exists='append', index=False)
            
            print(f"âœ… {len(recommendations)}ê°œ í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âŒ í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def show_enhanced_summary(self):
        """í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        try:
            print("\nğŸ“Š í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ ìš”ì•½:")
            
            # ì „ì²´ ì¶”ì²œ ìˆ˜
            total_count = pd.read_sql("SELECT COUNT(*) as total FROM enhanced_testresult", self.engine)
            print(f"   - ì´ ì¶”ì²œ ìˆ˜: {total_count.iloc[0]['total']}ê°œ")
            
            # í•™ìƒë³„ ì¶”ì²œ ìˆ˜
            student_count = pd.read_sql("SELECT COUNT(DISTINCT student_id) as students FROM enhanced_testresult", self.engine)
            print(f"   - ì¶”ì²œ ëŒ€ìƒ í•™ìƒ: {student_count.iloc[0]['students']}ëª…")
            
            # ì ìˆ˜ í†µê³„
            score_stats = pd.read_sql("""
                SELECT 
                    AVG(final_score) as avg_final_score,
                    AVG(semantic_similarity) as avg_semantic,
                    AVG(course_industry_score) as avg_course_industry,
                    AVG(location_score) as avg_location,
                    AVG(diversity_score) as avg_diversity,
                    AVG(freshness_score) as avg_freshness
                FROM enhanced_testresult
            """, self.engine)
            
            print(f"\nğŸ“ˆ ì ìˆ˜ í†µê³„:")
            print(f"   â€¢ ìµœì¢… ì ìˆ˜ í‰ê· : {score_stats.iloc[0]['avg_final_score']:.4f}")
            print(f"   â€¢ ì˜ë¯¸ì  ìœ ì‚¬ë„ í‰ê· : {score_stats.iloc[0]['avg_semantic']:.4f}")
            print(f"   â€¢ ê³¼ì •-ì‚°ì—… ë§¤ì¹­ í‰ê· : {score_stats.iloc[0]['avg_course_industry']:.4f}")
            print(f"   â€¢ ì§€ì—­ ì ìˆ˜ í‰ê· : {score_stats.iloc[0]['avg_location']:.4f}")
            print(f"   â€¢ ë‹¤ì–‘ì„± ì ìˆ˜ í‰ê· : {score_stats.iloc[0]['avg_diversity']:.4f}")
            print(f"   â€¢ ìµœì‹ ì„± ì ìˆ˜ í‰ê· : {score_stats.iloc[0]['avg_freshness']:.4f}")
            
            # ìƒìœ„ ì¶”ì²œ íšŒì‚¬ (ë‹¤ì–‘ì„± ê³ ë ¤)
            top_companies = pd.read_sql("""
                SELECT recommended_company, COUNT(*) as count 
                FROM enhanced_testresult 
                WHERE recommendation_rank = 1 
                GROUP BY recommended_company 
                ORDER BY count DESC 
                LIMIT 10
            """, self.engine)
            
            print(f"\nğŸ† ìƒìœ„ ì¶”ì²œ íšŒì‚¬ (ë‹¤ì–‘ì„± ê³ ë ¤):")
            for idx, row in top_companies.iterrows():
                print(f"   â€¢ {row['recommended_company']}: {row['count']}íšŒ")
            
            # ì§€ì—­ë³„ ë¶„í¬
            location_dist = pd.read_sql("""
                SELECT recommended_location, COUNT(*) as count 
                FROM enhanced_testresult 
                GROUP BY recommended_location 
                ORDER BY count DESC 
                LIMIT 10
            """, self.engine)
            
            print(f"\nğŸ“ ì¶”ì²œ ì§€ì—­ë³„ ë¶„í¬:")
            for idx, row in location_dist.iterrows():
                print(f"   â€¢ {row['recommended_location']}: {row['count']}íšŒ")
            
            # ë¶€ì‚° ì§€ì—­ ì¶”ì²œ í™•ì¸
            busan_recommendations = pd.read_sql("""
                SELECT COUNT(*) as count 
                FROM enhanced_testresult 
                WHERE recommended_location LIKE '%ë¶€ì‚°%'
            """, self.engine)
            
            print(f"\nğŸŒŠ ë¶€ì‚° ì§€ì—­ ì¶”ì²œ: {busan_recommendations.iloc[0]['count']}íšŒ")
            
        except Exception as e:
            print(f"âŒ í–¥ìƒëœ ìš”ì•½ ì¶œë ¥ ì˜¤ë¥˜: {e}")
    
    def run_enhanced_system(self):
        """í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        print("ğŸš€ í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 1. í–¥ìƒëœ í…Œì´ë¸” ìƒì„±
        if not self.create_enhanced_testresult_table():
            return False
        
        # 2. ì±„ìš© ë°ì´í„° ë¡œë“œ ë° í†µí•©
        job_data_df = self.load_and_merge_job_data()
        if job_data_df is None:
            return False
        
        # 3. í•™ìƒ í”„ë¡œí•„ ì¤€ë¹„
        student_profiles = self.prepare_student_profiles()
        if not student_profiles:
            return False
        
        # 4. í–¥ìƒëœ ì¶”ì²œ ìƒì„±
        recommendations = self.generate_enhanced_recommendations(student_profiles, job_data_df)
        
        # 5. í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ ì €ì¥
        if self.save_enhanced_recommendations(recommendations):
            # 6. í–¥ìƒëœ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            self.show_enhanced_summary()
            
            print("\nğŸ‰ í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
            print("ğŸ“Š enhanced_testresult í…Œì´ë¸”ì—ì„œ í–¥ìƒëœ ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return True
        else:
            print("\nâŒ í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨!")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í–¥ìƒëœ SBERT ê¸°ë°˜ í•™ìƒ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘...")
    
    # í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    enhanced_system = EnhancedRecommendationSystem()
    
    if enhanced_system is None:
        print("âŒ í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨!")
        return
    
    # í–¥ìƒëœ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í–‰
    success = enhanced_system.run_enhanced_system()
    
    if success:
        print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
