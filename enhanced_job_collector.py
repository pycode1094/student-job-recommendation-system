import requests
import pandas as pd
from sqlalchemy import create_engine
import warnings
import time
from datetime import datetime, timedelta
import logging
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_job_collector.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def get_enhanced_job_data():
    """í–¥ìƒëœ API íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘"""
    try:
        access_key = "VOT7qjrkXGwLGfkT0obOaOk7Hb8Wf9pEB75RgvZKNTNd08Ky7a"
        
        # 2ì£¼ ì „ íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°
        two_weeks_ago = datetime.now() - timedelta(weeks=2)
        two_weeks_ago_ts = int(two_weeks_ago.timestamp())
        
        logging.info(f"2ì£¼ ì „ íƒ€ì„ìŠ¤íƒ¬í”„: {two_weeks_ago_ts} ({two_weeks_ago.strftime('%Y-%m-%d %H:%M:%S')})")
        
        # í˜ì´ì§€ë„¤ì´ì…˜ì„ ìœ„í•œ ë³€ìˆ˜
        start = 0
        count = 100
        all_records = []
        
        # í–¥ìƒëœ API íŒŒë¼ë¯¸í„°
        base_params = {
            'access-key': access_key,
            'count': count,
            'fields': 'posting-date,expiration-date,keyword-code,count',  # ì¶”ê°€ í•„ë“œ ìš”ì²­
            'sort': 'pd',  # ê²Œì‹œì¼ ì—­ìˆœ
            'sr': 'directhire'  # í—¤ë“œí—ŒíŒ…/íŒŒê²¬ì—…ì²´ ì œì™¸
        }
        
        while True:
            params = base_params.copy()
            params['start'] = start
            
            url = "https://oapi.saramin.co.kr/job-search"
            response = requests.get(url, params=params, headers={"Accept": "application/json"})
            data = response.json()
            
            job_data = data.get("jobs", {}).get("job", [])
            
            if not job_data:
                break
                
            if isinstance(job_data, dict):
                job_data = [job_data]
            
            # 2ì£¼ ì´ë‚´ ë°ì´í„°ë§Œ í•„í„°ë§
            filtered_jobs = []
            for job in job_data:
                posting_ts = job.get("posting-timestamp")
                if posting_ts and int(posting_ts) >= two_weeks_ago_ts:
                    filtered_jobs.append(job)
                else:
                    break
            
            if not filtered_jobs:
                break
                
            # í–¥ìƒëœ íŒŒì‹±
            for job in filtered_jobs:
                record = {
                    "job_id": job.get("id"),
                    "url": job.get("url"),
                    "active": job.get("active"),
                    "company_name": job.get("company", {}).get("detail", {}).get("name"),
                    "company_type": job.get("company", {}).get("detail", {}).get("type", {}).get("name"),  # íšŒì‚¬ ìœ í˜•
                    "company_size": job.get("company", {}).get("detail", {}).get("size", {}).get("name"),  # íšŒì‚¬ ê·œëª¨
                    "title": job.get("position", {}).get("title"),
                    "industry": job.get("position", {}).get("industry", {}).get("name"),
                    "industry_code": job.get("position", {}).get("industry", {}).get("code"),  # ì‚°ì—… ì½”ë“œ
                    "job_type": job.get("position", {}).get("job-type", {}).get("name"),
                    "job_type_code": job.get("position", {}).get("job-type", {}).get("code"),  # ì§ë¬´ ìœ í˜• ì½”ë“œ
                    "location": job.get("position", {}).get("location", {}).get("name"),
                    "location_code": job.get("position", {}).get("location", {}).get("code"),  # ì§€ì—­ ì½”ë“œ
                    "experience": job.get("position", {}).get("experience-level", {}).get("name"),
                    "experience_code": job.get("position", {}).get("experience-level", {}).get("code"),  # ê²½ë ¥ ì½”ë“œ
                    "education": job.get("position", {}).get("required-education-level", {}).get("name"),
                    "education_code": job.get("position", {}).get("required-education-level", {}).get("code"),  # í•™ë ¥ ì½”ë“œ
                    "salary": job.get("salary", {}).get("name"),
                    "salary_code": job.get("salary", {}).get("code"),  # ê¸‰ì—¬ ì½”ë“œ
                    "posting_ts": job.get("posting-timestamp"),
                    "expiration_ts": job.get("expiration-timestamp"),
                    "keyword_code": job.get("keyword-code"),  # í‚¤ì›Œë“œ ì½”ë“œ
                    "view_count": job.get("count", {}).get("view"),  # ì¡°íšŒìˆ˜
                    "apply_count": job.get("count", {}).get("apply"),  # ì§€ì›ììˆ˜
                    "posting_date": job.get("posting-date"),  # ê²Œì‹œì¼
                    "expiration_date": job.get("expiration-date"),  # ë§ˆê°ì¼
                }
                all_records.append(record)
            
            logging.info(f"í˜ì´ì§€ {start//count + 1}: {len(filtered_jobs)}ê°œ ìˆ˜ì§‘ (ì´ {len(all_records)}ê°œ)")
            
            # ë‹¤ìŒ í˜ì´ì§€ë¡œ
            start += count
            
            # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ë”œë ˆì´
            time.sleep(0.5)
        
        return all_records
        
    except Exception as e:
        logging.error(f"API ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return []

def create_enhanced_job_table():
    """í–¥ìƒëœ ì±„ìš© ì •ë³´ í…Œì´ë¸” ìƒì„±"""
    try:
        import pymysql
        connection = pymysql.connect(
            host='127.0.0.1',
            user='root',
            password='15861',
            port=3306,
            database='job_recoder',
            charset='utf8mb4'
        )
        
        cursor = connection.cursor()
        
        # í–¥ìƒëœ í…Œì´ë¸” ìƒì„± SQL
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS enhanced_job_postings (
            id INT AUTO_INCREMENT PRIMARY KEY,
            job_id VARCHAR(50) UNIQUE,
            url TEXT,
            active TINYINT,
            company_name VARCHAR(200),
            company_type VARCHAR(100),
            company_size VARCHAR(100),
            title VARCHAR(500),
            industry VARCHAR(100),
            industry_code VARCHAR(20),
            job_type VARCHAR(100),
            job_type_code VARCHAR(20),
            location VARCHAR(200),
            location_code VARCHAR(100),
            experience VARCHAR(100),
            experience_code VARCHAR(20),
            education VARCHAR(100),
            education_code VARCHAR(20),
            salary VARCHAR(200),
            salary_code VARCHAR(20),
            posting_ts VARCHAR(50),
            expiration_ts VARCHAR(50),
            keyword_code VARCHAR(500),
            view_count INT,
            apply_count INT,
            posting_date VARCHAR(50),
            expiration_date VARCHAR(50),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            INDEX idx_job_id (job_id),
            INDEX idx_company_name (company_name),
            INDEX idx_industry (industry),
            INDEX idx_industry_code (industry_code),
            INDEX idx_job_type (job_type),
            INDEX idx_location (location),
            INDEX idx_experience (experience),
            INDEX idx_education (education),
            INDEX idx_keyword_code (keyword_code(100))
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """
        
        cursor.execute(create_table_sql)
        connection.commit()
        print("âœ… í–¥ìƒëœ í…Œì´ë¸” ìƒì„± ì™„ë£Œ: enhanced_job_postings")
        
        cursor.close()
        connection.close()
        
    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

def insert_enhanced_job_data(records):
    """í–¥ìƒëœ ì±„ìš© ë°ì´í„° ì‚½ì…"""
    try:
        if not records:
            logging.info("ì‚½ì…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        df = pd.DataFrame(records)
        
        # SQLAlchemy ì—”ì§„ ìƒì„±
        engine = create_engine(
            'mysql+pymysql://root:15861@127.0.0.1:3306/job_recoder?charset=utf8mb4'
        )
        
        # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ê¸°ì¡´ ë°ì´í„° í™•ì¸
        existing_jobs_query = "SELECT job_id FROM enhanced_job_postings"
        existing_jobs = pd.read_sql(existing_jobs_query, engine)
        existing_job_ids = set(existing_jobs['job_id'].tolist())
        
        # ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•„í„°ë§
        new_df = df[~df['job_id'].isin(existing_job_ids)]
        
        if new_df.empty:
            logging.info("ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„° ì‚½ì…
        new_df.to_sql(
            name='enhanced_job_postings',
            con=engine,
            if_exists='append',
            index=False,
            method='multi',
            chunksize=100
        )
        
        logging.info(f"âœ… í–¥ìƒëœ ë°ì´í„° ì‚½ì… ì™„ë£Œ: {len(new_df)}ê°œ ë ˆì½”ë“œ (ì´ ìˆ˜ì§‘: {len(df)}ê°œ)")
        
    except Exception as e:
        logging.error(f"âŒ ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í–¥ìƒëœ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì‹œì‘")
    
    # 1. í–¥ìƒëœ í…Œì´ë¸” ìƒì„±
    create_enhanced_job_table()
    
    # 2. í–¥ìƒëœ ë°ì´í„° ìˆ˜ì§‘
    records = get_enhanced_job_data()
    
    # 3. ë°ì´í„° ì‚½ì…
    insert_enhanced_job_data(records)
    
    print("ğŸ‰ í–¥ìƒëœ ì±„ìš© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 